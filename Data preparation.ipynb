{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Подготовка данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Изначальный датасет довольно избыточный, поэтому для проведения задания мы пользуемся этим ноутбуком, чтобы взять только нужную часть"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Скачать весь датасет (~5 Гб) можно по этой ссылке: https://drive.google.com/file/d/1CUZnBtYwifVXS21yVg62T-vrPVayso5H/view\n",
    "Файл с отсутствующими скелетами: https://github.com/shahroudy/NTURGB-D/blob/master/Matlab/NTU_RGBD_samples_with_missing_skeletons.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "\n",
    "use_cuda = torch.cuda.is_available()\n",
    "# device = torch.device(\"cpu\")\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2020-12-01 22:37:49--  https://raw.githubusercontent.com/shahroudy/NTURGB-D/master/Matlab/NTU_RGBD_samples_with_missing_skeletons.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.36.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.36.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 6554 (6.4K) [text/plain]\n",
      "Saving to: ‘NTU_RGBD_samples_with_missing_skeletons.txt’\n",
      "\n",
      "NTU_RGBD_samples_wi 100%[===================>]   6.40K  --.-KB/s    in 0s      \n",
      "\n",
      "2020-12-01 22:37:52 (21.3 MB/s) - ‘NTU_RGBD_samples_with_missing_skeletons.txt’ saved [6554/6554]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/shahroudy/NTURGB-D/master/Matlab/NTU_RGBD_samples_with_missing_skeletons.txt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preparation.ipynb\r\n",
      "\u001b[1m\u001b[36mLSTM\u001b[m\u001b[m\r\n",
      "LSTM.zip\r\n",
      "NTU_RGBD_samples_with_missing_skeletons.txt\r\n",
      "\u001b[1m\u001b[36mnturgb+d_skeletons\u001b[m\u001b[m\r\n",
      "vox2018.pdf\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"~/nturgb+d_skeletons/\"\n",
    "#### список отсутсвующих элементов так же будет доступен \n",
    "broken_files_path = \"~/NTU_RGBD_samples_with_missing_skeletons.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_subjects = list(range(0, 28)) #количество людей выполняющих действия\n",
    "training_classes = [8, 10, 22, 23, 27, 21] #классы которые будем использовать для обучения, полный список прдставлен тут https://github.com/shahroudy/NTURGB-D\n",
    "training_cameras = [1, 2, 3] \n",
    "\n",
    "max_body_true = 1\n",
    "max_body_kinect = 1\n",
    "\n",
    "num_joint = 25\n",
    "max_frame = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(data_path, broken_files_path):\n",
    "    labels = []\n",
    "    files = []\n",
    "    action_classes = {}\n",
    "    counter = 0\n",
    "    files_counter = {}\n",
    "              \n",
    "    with open(broken_files_path, 'r') as f:\n",
    "        broken_files = f.read().split(\"\\n\")\n",
    "\n",
    "    raw_files = os.listdir(data_path)\n",
    "    num_frames = 0\n",
    "\n",
    "    for filename in raw_files:\n",
    "        if filename not in broken_files:\n",
    "            action_class = int(filename[filename.find('A') + 1:filename.find('A') + 4])\n",
    "            subject_id = int(filename[filename.find('P') + 1:filename.find('P') + 4])\n",
    "            camera_id = int(filename[filename.find('C') + 1:filename.find('C') + 4])\n",
    "            if action_class in training_classes and camera_id in training_cameras:  #and subject_id in training_subjects:\n",
    "                if action_class in action_classes:\n",
    "                    if files_counter[action_class] < 120:\n",
    "                        files.append([filename,action_classes[action_class]])\n",
    "                        files_counter[action_class] = files_counter[action_class] + 1\n",
    "                else:\n",
    "                    action_classes.update({action_class : counter})\n",
    "                    files_counter.update({action_class : 1})\n",
    "                    counter+=1\n",
    "                    files.append([filename,action_classes[action_class]])\n",
    "#                     labels.append([action_class])\n",
    "    print(\"action classes: \", action_classes)\n",
    "    print(\"action files: \", files_counter)\n",
    "    \n",
    "    return files, action_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nonzero_std(s): \n",
    "    index = s.sum(-1).sum(-1) != 0  \n",
    "    s = s[index]\n",
    "    if len(s) != 0:\n",
    "        s = s[:, :, 0].std() + s[:, :, 1].std() + s[:, :, 2].std()  \n",
    "    else:\n",
    "        s = 0\n",
    "    return s\n",
    "\n",
    "def read_skeleton_filter(file):\n",
    "    with open(file, 'r') as f:\n",
    "        skeleton_sequence = {}\n",
    "        skeleton_sequence['numFrame'] = int(f.readline())\n",
    "        skeleton_sequence['frameInfo'] = []\n",
    "        for t in range(skeleton_sequence['numFrame']):\n",
    "            frame_info = {}\n",
    "            frame_info['numBody'] = int(f.readline())\n",
    "            frame_info['bodyInfo'] = []\n",
    "\n",
    "            for m in range(frame_info['numBody']):\n",
    "                body_info = {}\n",
    "                body_info_key = [\n",
    "                    'bodyID', 'clipedEdges', 'handLeftConfidence',\n",
    "                    'handLeftState', 'handRightConfidence', 'handRightState',\n",
    "                    'isResticted', 'leanX', 'leanY', 'trackingState'\n",
    "                ]\n",
    "                body_info = {\n",
    "                    k: float(v)\n",
    "                    for k, v in zip(body_info_key, f.readline().split())\n",
    "                }\n",
    "                body_info['numJoint'] = int(f.readline())\n",
    "                body_info['jointInfo'] = []\n",
    "                for v in range(body_info['numJoint']):\n",
    "                    joint_info_key = [\n",
    "                        'x', 'y', 'z', 'depthX', 'depthY', 'colorX', 'colorY',\n",
    "                        'orientationW', 'orientationX', 'orientationY',\n",
    "                        'orientationZ', 'trackingState'\n",
    "                    ]\n",
    "                    joint_info = {\n",
    "                        k: float(v)\n",
    "                        for k, v in zip(joint_info_key, f.readline().split())\n",
    "                    }\n",
    "                    body_info['jointInfo'].append(joint_info)\n",
    "                frame_info['bodyInfo'].append(body_info)\n",
    "            skeleton_sequence['frameInfo'].append(frame_info)\n",
    "\n",
    "    return skeleton_sequence\n",
    "\n",
    "def read_xyz(file, max_body=1, num_joint=25):\n",
    "    seq_info = read_skeleton_filter(file)\n",
    "    data = np.zeros((max_body, seq_info['numFrame'], num_joint, 3))\n",
    "    for n, f in enumerate(seq_info['frameInfo']):\n",
    "        for m, b in enumerate(f['bodyInfo']):\n",
    "            for j, v in enumerate(b['jointInfo']):\n",
    "                if m < max_body and j < num_joint:\n",
    "                    data[m, n, j, :] = [v['x'], v['y'], v['z']]\n",
    "\n",
    "                else:\n",
    "                    pass\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### В этой функции меняем количество фремйов подаваемых на вход модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_coords_blocks(test_file, chonk_len = 45):   \n",
    "    frame_counter = 0\n",
    "    new_labels = []\n",
    "    new_frames = []\n",
    "    blocks = []\n",
    "    \n",
    "    test_frames = read_xyz(data_path + test_file[0])[0]\n",
    "    label = test_file[1]\n",
    "    slice_len = chonk_len * int(len(test_frames)/chonk_len)\n",
    "\n",
    "\n",
    "    for index in range(len(test_frames[:slice_len])):\n",
    "        frame_counter += 1\n",
    "        new_frames.append(test_frames[index].flatten())\n",
    "        if frame_counter == chonk_len:\n",
    "            frame_counter = 0\n",
    "            blocks.append(np.array(new_frames))\n",
    "            new_labels = new_labels + [label]\n",
    "            new_frames = []\n",
    "       \n",
    "            \n",
    "    return blocks, new_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "joints_framework = ['neck', 'nose', 'mid_hip',\n",
    "                 'l_sho', 'l_elb',\n",
    "                 'l_wri', 'l_hip',\n",
    "                 'l_knee', 'l_ank',\n",
    "                 'r_sho', 'r_elb',\n",
    "                 'r_wri', 'r_hip',\n",
    "                 'r_kne', 'r_ank',\n",
    "                 'r_eye', 'l_eye',\n",
    "                 'r_ear', 'l_ear']\n",
    "\n",
    "\n",
    "joints_framework_in_work = ['nose','l_sho', 'l_elb','l_wri','r_sho','r_elb', 'r_wri', 'l_hip','l_knee','l_ank','r_hip','r_kne','r_ank','neck']\n",
    "upper_joints_framework = ['nose','l_sho', 'l_elb','l_wri','r_sho','r_elb', 'r_wri', 'l_hip','l_knee','l_ank','r_hip','r_kne','r_ank','neck']\n",
    "\n",
    "\n",
    "\n",
    "SKELETON_EDGES = np.array([[11, 10], [10, 9], [9, 0], [0, 3], [3, 4], [4, 5], [0, 6], [6, 7], [7, 8], [0, 12],\n",
    "                               [12, 13], [13, 14], [1, 14], [1, 15], [15, 16], [1, 17], [17, 18]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "bone_pairs = (\n",
    "    (1, 2), (2, 21), (3, 21), (4, 3), (5, 21), (6, 5),\n",
    "    (7, 6), (8, 7), (9, 21), (10, 9), (11, 10), (12, 11),\n",
    "    (13, 1), (14, 13), (15, 14), (16, 15), (17, 1), (18, 17),\n",
    "    (19, 18), (20, 19), (22, 23), (21, 21), (23, 8), (24, 25),(25, 12)\n",
    ")\n",
    "\n",
    "bone_pairs_in_work = (\n",
    "    (1, 14), \n",
    "    (14, 2), (2, 3), (3, 4),\n",
    "    (14, 5), (5, 6), (6, 7), \n",
    "    (14, 8), (8, 9), (9, 10),\n",
    "    (14, 11), (11, 12), (12, 13))\n",
    "\n",
    "\n",
    "joints_names = ['spinebase', 'spinemid', 'neck', 'head','l_sho', 'l_elb','l_wri','l_hand','r_sho','r_elb', 'r_wri', 'r_hand','l_hip','l_knee','l_ank','l_fool','r_hip','r_knee','r_ank','r_foot','spineshoulder','l_tip','l_thumb','r_tip','r_thunb']\n",
    "joints_in_work = [ 'head','l_sho', 'l_elb','l_wri','r_sho','r_elb', 'r_wri', 'l_hip','l_knee','l_ank','r_hip','r_knee','r_ank','spineshoulder']\n",
    "upper_joints = [ 'head','l_sho', 'l_elb','l_wri','r_sho','r_elb', 'r_wri', 'l_hip','l_knee','l_ank','r_hip','r_knee','r_ank','spineshoulder']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '~/NTU_RGBD_samples_with_missing_skeletons.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-fc361d9dbcbf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m##### список файлов с лейблами на каждый файл\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mworking_files_with_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbroken_files_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-17-c4afe67daee4>\u001b[0m in \u001b[0;36mread_data\u001b[0;34m(data_path, broken_files_path)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mfiles_counter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbroken_files_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mbroken_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '~/NTU_RGBD_samples_with_missing_skeletons.txt'"
     ]
    }
   ],
   "source": [
    "##### список файлов с лейблами на каждый файл \n",
    "working_files_with_labels, action_classes = read_data(data_path, broken_files_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'action_classes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-880ecdfd18dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mLABELS\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maction_classes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'action_classes' is not defined"
     ]
    }
   ],
   "source": [
    "LABELS = {v: k for k, v in action_classes.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Здесь выносится сгенерированный список лейблов с номером класса. Эту переменную можно перенести ручками, а можно автоматизировать. Тут на ваше усмотрение, автору немного лень :) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(LABELS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(working_files_with_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "labels = []\n",
    "##########################################################################\n",
    "numbers = {0: 0, 1 : 0, 2 : 0, 3 : 0, 4 :0} #####\n",
    "##################################################################\n",
    "for file in working_files_with_labels:\n",
    "    frames_blocks, label = create_coords_blocks(file)\n",
    "    if label != [] and numbers[label[0]] <= 150:\n",
    "        numbers[label[0]] = numbers[label[0]] + len(label)\n",
    "        data = data + frames_blocks\n",
    "        labels = labels + label\n",
    "data_np = np.asarray(data)\n",
    "labels_np = np.asarray(labels)\n",
    "\n",
    "data_sq = data_np.reshape(len(data_np), -1)\n",
    "test_data = pd.DataFrame(data_sq)\n",
    "test_labels = pd.DataFrame(labels_np)\n",
    "test_data['labels'] = test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ваш итоговый фалй для загрузки на колаб"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.to_csv(\"skeletons_classes_1_30.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
